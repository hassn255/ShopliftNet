{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30837,
     "status": "ok",
     "timestamp": 1760732963706,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "Xap22ffCVZg2",
    "outputId": "8383b40b-4aa2-4a8e-e261-a1d54b1f8598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1760721158553,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "8IqiGp3PW0Li"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5575,
     "status": "ok",
     "timestamp": 1760721117952,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "jAgOkWnIgQjn",
    "outputId": "1baa7524-8eda-4114-949a-e893a2008edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 855\n"
     ]
    }
   ],
   "source": [
    "folder = r\"/content/drive/MyDrive/project/Shop DataSet\"\n",
    "count = sum(len(files) for _, _, files in os.walk(folder))\n",
    "print(\"Total files:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXIh4jJT1rtC"
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P534T3qu15Xp"
   },
   "source": [
    "## Data Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1760721120751,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "L-Z38Bc-Wwbn"
   },
   "outputs": [],
   "source": [
    "#  Video Dataset\n",
    "# -------------------------\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root_dir, num_frames=16, train=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.videos = []\n",
    "        self.num_frames = num_frames\n",
    "        self.train = train\n",
    "\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "\n",
    "        for label, class_name in enumerate(self.classes):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            for file in os.listdir(class_path):\n",
    "                if file.endswith(('.mp4', '.avi', '.mov')):\n",
    "                    self.videos.append({\n",
    "                        'path': os.path.join(class_path, file),\n",
    "                        'label': label\n",
    "                    })\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                 std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "\n",
    "    def read_video(self, path):\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "        return frames\n",
    "\n",
    "    def sample_frames(self, frames):\n",
    "        total = len(frames)\n",
    "        if total == 0:\n",
    "            return None\n",
    "        indices = np.linspace(0, total - 1, self.num_frames, dtype=int)\n",
    "        return [frames[i] for i in indices]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_info = self.videos[idx]\n",
    "        frames = self.read_video(video_info['path'])\n",
    "        frames = self.sample_frames(frames)\n",
    "        if frames is None:\n",
    "            raise ValueError(f\"No frames found in {video_info['path']}\")\n",
    "        frames = [self.transform(Image.fromarray(f)) for f in frames]\n",
    "        video_tensor = torch.stack(frames)  # [T, C, H, W]\n",
    "        label = torch.tensor(video_info['label'])\n",
    "        return video_tensor, label, video_info['path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1760721168886,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "V359_8_W_hch"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights = R3D_18_Weights.DEFAULT\n",
    "model = r3d_18(weights=weights)\n",
    "model.fc = nn.Identity()  # remove classification layer\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1760722079100,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "1HgGT1B3_rC8"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_and_save_features(dataset, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    loader = DataLoader(dataset, batch_size=4, shuffle=False, num_workers = 4, pin_memory = True)\n",
    "\n",
    "    for videos, labels, paths in tqdm(loader, desc=\"Extracting video features\"):\n",
    "        videos = videos.to(device)\n",
    "        videos = videos.permute(0, 2, 1, 3, 4)\n",
    "        feats = F.normalize(model(videos), dim=1)  # [B, 512]\n",
    "\n",
    "        for feat, path in zip(feats, paths):\n",
    "            rel_path = Path(path).relative_to(dataset.root_dir)\n",
    "            save_path = Path(save_dir) / rel_path.with_suffix(\".pt\")\n",
    "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(feat.cpu(), save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 593605,
     "status": "ok",
     "timestamp": 1760722675190,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "rTQ9AOeG_vQn",
    "outputId": "1ec51335-acc6-4367-914a-eefb8c05a4a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Extracting video features: 100%|██████████| 214/214 [09:53<00:00,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = VideoDataset(\"/content/drive/MyDrive/project/Shop DataSet\")\n",
    "extract_and_save_features(dataset, \"/content/drive/MyDrive/project/features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1760721910043,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "jjB8h04AM40c",
    "outputId": "2a863812-7292-4a12-d5cb-514a7b7df997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7638,
     "status": "ok",
     "timestamp": 1760732997291,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "4_kqmmgp2EeT"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1760734235432,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "p_G_eyyf2UpY"
   },
   "outputs": [],
   "source": [
    "FEATURES_DIR = Path(r\"/content/drive/MyDrive/project/features\")\n",
    "ORIGINAL_DATASET = Path(r\"/content/drive/MyDrive/project/Shop DataSet\")\n",
    "OUTPUT_DIR = Path(r\"/content/drive/MyDrive/project/clean Shop Dataset\")\n",
    "THRESHOLD = 0.999  # similarity threshold for duplicates\n",
    "VAL_RATIO = 0.2   # 20% validation split\n",
    "\n",
    "CLASSES = [\"shop lifters\", \"non shop lifters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1760734235657,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "0PKVKEvluvh9"
   },
   "outputs": [],
   "source": [
    "def load_features(class_name):\n",
    "    class_dir = FEATURES_DIR / class_name\n",
    "    paths = list(class_dir.rglob(\"*.pt\"))\n",
    "    feats = [torch.load(p) for p in paths]\n",
    "    feats = torch.stack(feats)\n",
    "    feats = F.normalize(feats, dim=1)\n",
    "    return feats, paths\n",
    "\n",
    "def find_duplicates(feats, paths, threshold=0.95):\n",
    "    sim_matrix = feats @ feats.T  # cosine similarity (since normalized)\n",
    "    sim_matrix.fill_diagonal_(0)\n",
    "    to_remove = set()\n",
    "\n",
    "    for i in range(sim_matrix.size(0)):\n",
    "        if i in to_remove:\n",
    "            continue\n",
    "        duplicates = (sim_matrix[i] > threshold).nonzero(as_tuple=True)[0].tolist()\n",
    "        to_remove.update(duplicates)\n",
    "\n",
    "    keep_indices = [i for i in range(len(paths)) if i not in to_remove]\n",
    "\n",
    "    print(f\"number of duplicates {len(to_remove)}, number of to keep videos {len(keep_indices)} \")\n",
    "    return keep_indices\n",
    "\n",
    "def copy_videos(video_paths, output_dir):\n",
    "  for src_path in video_paths:\n",
    "      rel = src_path.relative_to(ORIGINAL_DATASET)\n",
    "      dst = output_dir / rel\n",
    "      dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "      if not dst.exists():  # avoid overwriting\n",
    "          shutil.copy2(src_path, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248601,
     "status": "ok",
     "timestamp": 1760734485488,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "HI4EawunuvTy",
    "outputId": "3ff963d3-f950-4769-f0f2-c907b7f05005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing class: shop lifters\n",
      "number of duplicates 76, number of to keep videos 248 \n",
      "\n",
      "Processing class: non shop lifters\n",
      "number of duplicates 253, number of to keep videos 278 \n",
      "\n",
      "✅ Done! Clean dataset created at: /content/drive/MyDrive/project/clean Shop Dataset\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR.mkdir(parents = True, exist_ok = True)\n",
    "for class_name in CLASSES:\n",
    "    print(f\"\\nProcessing class: {class_name}\")\n",
    "    feats, feat_paths = load_features(class_name)\n",
    "\n",
    "    video_paths = [\n",
    "        ORIGINAL_DATASET / class_name / (feat_path.stem + \".mp4\")\n",
    "        for feat_path in feat_paths\n",
    "    ]\n",
    "\n",
    "    # Find duplicates\n",
    "    keep_indices = find_duplicates(feats, video_paths, threshold=THRESHOLD)\n",
    "    clean_paths = [video_paths[i] for i in keep_indices]\n",
    "\n",
    "    # Split into train / validation\n",
    "    train_paths, val_paths = train_test_split(clean_paths, test_size=VAL_RATIO, random_state=42)\n",
    "\n",
    "    # Copy to new clean dataset\n",
    "    copy_videos(train_paths, OUTPUT_DIR / \"train\")\n",
    "    copy_videos(val_paths, OUTPUT_DIR / \"validation\")\n",
    "\n",
    "print(\"\\n✅ Done! Clean dataset created at:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 189,
     "status": "ok",
     "timestamp": 1760733816319,
     "user": {
      "displayName": "hassan elsayed",
      "userId": "03347226241831335202"
     },
     "user_tz": -180
    },
    "id": "R3RTOxFD4cDY",
    "outputId": "cc426711-2926-403d-e7a5-c06d79a2fc11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/project/features/shop lifters exists: True\n",
      "Number of .pt files: 324\n",
      "/content/drive/MyDrive/project/features/non shop lifters exists: True\n",
      "Number of .pt files: 531\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "FEATURES_DIR = Path(r\"/content/drive/MyDrive/project/features\")\n",
    "for class_name in [\"shop lifters\", \"non shop lifters\"]:\n",
    "    class_dir = FEATURES_DIR / class_name\n",
    "    print(class_dir, \"exists:\", class_dir.exists())\n",
    "    print(\"Number of .pt files:\", len(list(class_dir.rglob(\"*.pt\"))))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP4jvjT3+4W7is80aAHQusU",
   "collapsed_sections": [
    "zxJInAXV1paW"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
